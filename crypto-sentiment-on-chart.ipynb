{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e43aa20",
   "metadata": {},
   "source": [
    "# Crypto Sentiment on Chart Analysis\n",
    "\n",
    "This notebook aims to explore the potential relationship between sentiment on 4chan's Business and Finance board and the price action of selected cryptocurrencies. 4chan is a valuable source for sentiment analysis as its posts are freely accessible via its API, making it a cost-effective alternative to platforms like Twitter. The primary objective of this analysis is to investigate whether sentiment derived from 4chan posts can be correlated with the price movements of specific cryptocurrencies. By binning 4chan posts into specific time intervals and aligning them with cryptocurrency price charts, we can calculate a net sentiment score for each bin and observe any patterns or trends that may emerge. Here's how it works:\n",
    "\n",
    "- **Data Collection**: Scrape 4chan thread posts related to cryptocurrencies, focusing on the Business and Finance board. Then, organise the posts in chronological order.\n",
    "- **Datetime Binning**: Slot the post data into predefined datetime bins that correspond to intervals on a cryptocurrency price chart.\n",
    "- **Sentiment Analysis**: Perform sentiment analysis on the text data within each bin to categorize posts as bullish, neutral, or bearish.\n",
    "Sum the sentiment scores within each bin to generate a net sentiment score.\n",
    "- **Net Sentiment Score Calculation**: Calculate the net average sentiment score by subtracting the bearish sentiment score from the bullish sentiment score and then dividing with the number of predictions. A positive net sentiment score indicates a bullish sentiment, while a negative score indicates bearish sentiment.\n",
    "- **Analysis**: Compare the net sentiment scores with the corresponding price action in the cryptocurrency market. Investigate whether there is a discernible relationship between the sentiment on 4chan and the subsequent price movements.\n",
    "\n",
    "In this notebook, this analysis is demonstrated using cryptocurrency price data sourced from the Binance, OKX, and Bybit APIs and thread post data from 4chan's Business and Finance board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab73ff6-fa1f-46cc-900b-8268a0c14305",
   "metadata": {},
   "source": [
    "## Prepare your Environment\n",
    "\n",
    "Ensure that the 'venv' kernel is selected for this notebook. If not, click on 'Kernel' at the top bar, select 'Change Kernel...' and select 'crypto-trading-analysis' as the kernel. For convenience, ensure that 'Always start the preferred kernel' is ticked. Click 'Select' to confirm the setting.\n",
    "\n",
    "Install the environment's dependencies using the command below. After installation, restart the kernel to use the updated packages. To restart, click on 'Kernel' at the top bar and select 'Restart Kernel' and click on 'Restart'. Please skip this step if you have already done it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d92236-023d-4e09-94c8-a65fcecd9c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ad883-ce63-4504-8af6-52998aedb87d",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f89e4a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 29.034008,
     "end_time": "2023-11-01T02:04:18.534845",
     "exception": false,
     "start_time": "2023-11-01T02:03:49.500837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from itertools import combinations\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from transformers import TextClassificationPipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from utils import calculate_profit, plot_strategy\n",
    "from data_manager import load_ts_df, process_data, sanitize_data, save_sentiment_score_df, load_presaved_df\n",
    "from social_media_analysis.data_manager import load_df_range as load_post_df_range\n",
    "\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = ''\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:10809'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:10809'\n",
    "os.environ['all_proxy'] = 'socks5://127.0.0.1:10808'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf0de13",
   "metadata": {},
   "source": [
    "## Process Price Dataframe\n",
    "\n",
    "- Before proceeding, ensure that the price data has been downloaded using ***'data_manager.py'***.\n",
    "- Enter the ***cex*** (Centralized Exchange) and ***interval*** values used for data download to load the relevant *.pkl* files and retrieve the dataframe.\n",
    "- All available pairs will be loaded by default.\n",
    "- Note that some pairs might be new and may lack sufficient data within the downloaded timeframe. Such pairs will be removed based on the ***nan_remove_threshold*** setting, which defines the maximum percentage of NaN values allowed relative to the total data points. For example, with a ***nan_remove_threshold*** of 0.1, if a pair has 100 data points and 15 are NaN, the pair will be excluded.\n",
    "- From the remaining pairs, you can filter the top N volume pairs using the ***top_n_volume_pairs*** parameter.\n",
    "- This part of the code will also ensure that all timeseries columns have the same number of data points.\n",
    "- The earliest and latest dates for all pairs will be recorded. These dates can then be used to determine the timeframe for slicing the data in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13057dad-759b-4606-b673-6b699765f2c1",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffa57f5-0ef6-49ca-847f-b439c1c63bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "cex = 'binance'\n",
    "interval = '1d'\n",
    "nan_remove_threshold = 0.1\n",
    "\n",
    "# Select only the top N mean volume pairs from the selected pairs to analyse.\n",
    "top_n_volume_pairs = 100\n",
    "\n",
    "# Select volume filter mode. Options: ['rolling', 'mean'].\n",
    "volume_filter_mode = 'rolling'\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa468df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode: Crypto Sentiment on Chart Analysis\n",
      "CEX: Binance\n",
      "Interval: 1d\n",
      "NaN Remove Threshold: 0.1\n",
      "Top N Volume Pairs: 100\n",
      "Volume Filter Mode: Rolling\n",
      "\n",
      "Columns that contains NaN values:\n",
      "               Pair  NaN Count          Remark\n",
      "5           DIAUSDT        359       To Remove\n",
      "13        EIGENUSDT        358       To Remove\n",
      "74          COSUSDT        357       To Remove\n",
      "61          REIUSDT        354       To Remove\n",
      "37        HMSTRUSDT        353       To Remove\n",
      "43         LOKAUSDT        351       To Remove\n",
      "83         GHSTUSDT        350       To Remove\n",
      "31          FIOUSDT        347       To Remove\n",
      "99         CATIUSDT        347       To Remove\n",
      "0          FIDAUSDT        346       To Remove\n",
      "96          KDAUSDT        345       To Remove\n",
      "70        NEIROUSDT        343       To Remove\n",
      "85   1MBABYDOGEUSDT        343       To Remove\n",
      "42       UXLINKUSDT        342       To Remove\n",
      "2           POLUSDT        340       To Remove\n",
      "100       AERGOUSDT        337       To Remove\n",
      "8           RPLUSDT        336       To Remove\n",
      "75     NEIROETHUSDT        333       To Remove\n",
      "11        QUICKUSDT        333       To Remove\n",
      "54          BSWUSDT        332       To Remove\n",
      "32         FLUXUSDT        330       To Remove\n",
      "110       CHESSUSDT        325       To Remove\n",
      "52         MBOXUSDT        324       To Remove\n",
      "102        NULSUSDT        322       To Remove\n",
      "90         DOGSUSDT        322       To Remove\n",
      "114        VIDTUSDT        319       To Remove\n",
      "10       ALPACAUSDT        318       To Remove\n",
      "3           SUNUSDT        318       To Remove\n",
      "9        POPCATUSDT        318       To Remove\n",
      "71        BRETTUSDT        316       To Remove\n",
      "97        VOXELUSDT        316       To Remove\n",
      "63          SYSUSDT        315       To Remove\n",
      "76          SYNUSDT        312       To Remove\n",
      "65            GUSDT        311       To Remove\n",
      "109      BANANAUSDT        311       To Remove\n",
      "68         RAREUSDT        311       To Remove\n",
      "113      RENDERUSDT        291       To Remove\n",
      "50          ZROUSDT        255       To Remove\n",
      "103       LISTAUSDT        255       To Remove\n",
      "40           ZKUSDT        252       To Remove\n",
      "26          MEWUSDT        252       To Remove\n",
      "107          IOUSDT        246       To Remove\n",
      "92        TURBOUSDT        234       To Remove\n",
      "48          NOTUSDT        220       To Remove\n",
      "105          BBUSDT        217       To Remove\n",
      "60          REZUSDT        204       To Remove\n",
      "95         OMNIUSDT        191       To Remove\n",
      "6           TAOUSDT        185       To Remove\n",
      "17         SAGAUSDT        183       To Remove\n",
      "91         TNSRUSDT        182       To Remove\n",
      "87            WUSDT        177       To Remove\n",
      "53          ENAUSDT        176       To Remove\n",
      "21        ETHFIUSDT        161       To Remove\n",
      "115        BOMEUSDT        159       To Remove\n",
      "94        VANRYUSDT        156       To Remove\n",
      "80         AEVOUSDT        156       To Remove\n",
      "15        METISUSDT        155       To Remove\n",
      "25         MYROUSDT        148       To Remove\n",
      "41          TONUSDT        144       To Remove\n",
      "44          AXLUSDT        144       To Remove\n",
      "112      PORTALUSDT        143       To Remove\n",
      "66          GLMUSDT        136       To Remove\n",
      "39        MAVIAUSDT        135       To Remove\n",
      "45         STRKUSDT        134       To Remove\n",
      "57        PIXELUSDT        133       To Remove\n",
      "81           OMUSDT        127       To Remove\n",
      "29          DYMUSDT        121       To Remove\n",
      "47        RONINUSDT        120       To Remove\n",
      "69         ZETAUSDT        116       To Remove\n",
      "14          JUPUSDT        114       To Remove\n",
      "58          LSKUSDT        108       To Remove\n",
      "27          ALTUSDT        108       To Remove\n",
      "20         ONDOUSDT        103       To Remove\n",
      "86          WIFUSDT        101       To Remove\n",
      "51        MANTAUSDT        101       To Remove\n",
      "12          XAIUSDT         92       To Remove\n",
      "35           AIUSDT         91       To Remove\n",
      "108         NFPUSDT         79       To Remove\n",
      "22         MOVRUSDT         78       To Remove\n",
      "106         ACEUSDT         70       To Remove\n",
      "46     1000RATSUSDT         67       To Remove\n",
      "59      AUCTIONUSDT         67       To Remove\n",
      "55     1000SATSUSDT         64       To Remove\n",
      "84          JTOUSDT         60       To Remove\n",
      "16         ETHWUSDT         50       To Remove\n",
      "33         USTCUSDT         49       To Remove\n",
      "72          ONGUSDT         49       To Remove\n",
      "82        SUPERUSDT         48       To Remove\n",
      "36     1000BONKUSDT         44       To Remove\n",
      "38         PYTHUSDT         44       To Remove\n",
      "56        BEAMXUSDT         39       To Remove\n",
      "73          KASUSDT         39       To Remove\n",
      "67         NTRNUSDT         36  To Interpolate\n",
      "62          ILVUSDT         32  To Interpolate\n",
      "1        BADGERUSDT         31  To Interpolate\n",
      "104       STEEMUSDT         30  To Interpolate\n",
      "28         ORDIUSDT         29  To Interpolate\n",
      "7         TOKENUSDT         25  To Interpolate\n",
      "88          TWTUSDT         25  To Interpolate\n",
      "23         MEMEUSDT         25  To Interpolate\n",
      "4          CAKEUSDT         24  To Interpolate\n",
      "18          SNTUSDT         24  To Interpolate\n",
      "24          TIAUSDT         22  To Interpolate\n",
      "79          SLPUSDT         22  To Interpolate\n",
      "89         POWRUSDT         18  To Interpolate\n",
      "77        POLYXUSDT         16  To Interpolate\n",
      "111         GASUSDT         16  To Interpolate\n",
      "98          RIFUSDT         12  To Interpolate\n",
      "49          BSVUSDT         11  To Interpolate\n",
      "30         STPTUSDT          9  To Interpolate\n",
      "93         WAXPUSDT          9  To Interpolate\n",
      "78         ORBSUSDT          8  To Interpolate\n",
      "101        BONDUSDT          6  To Interpolate\n",
      "19      BIGTIMEUSDT          3  To Interpolate\n",
      "34        STRAXUSDT          2  To Interpolate\n",
      "64         LOOMUSDT          2  To Interpolate\n",
      "\n",
      "Removed 92 pairs as they contain too many NaN values.\n",
      "Successfully loaded candlestick dataframe for all available pairs.\n",
      "\n",
      "Earliest time series start date: 2023-10-09\n",
      "Latest time series end date: 2024-10-07\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMode: Crypto Sentiment on Chart Analysis\")\n",
    "print(\"CEX: {}\".format(str(cex).capitalize()))\n",
    "print(\"Interval: {}\".format(interval))\n",
    "print(\"NaN Remove Threshold: {}\".format(nan_remove_threshold))\n",
    "print(\"Top N Volume Pairs: {}\".format(top_n_volume_pairs))\n",
    "print(\"Volume Filter Mode: {}\".format(str(volume_filter_mode).capitalize()))\n",
    "\n",
    "merged_price_df = process_data('sentiment_on_chart', cex, interval, nan_remove_threshold, [],\n",
    "                 top_n_volume_pairs, volume_filter_mode)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66614d32-8464-4265-b709-8a2d7a681acf",
   "metadata": {},
   "source": [
    "## Sanitize the price dataframe\n",
    "\n",
    "- Slice the dataframe according to the specified ***start_date*** and ***end_date***. Choose ***start_date*** and ***end_date*** within the timeframe shown by the output of the previous cell.\n",
    "- Interpolate any missing values in the dataframe.\n",
    "- If the interpolation fails, just backfill with the latest valid value.\n",
    "- Verify that all is as expected with an `assert` and check the shapes of 2 random pairs, which should have the same dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705815e-af19-428e-b1b2-2f1ffd123c1b",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57b0551a-033f-4b9a-8ac0-d82ceef0861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-10-07'\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c499c5-4313-40e1-bb52-ae3462912b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-Data Check-\n",
      "BTCUSDT's Data Shape: (281, 1)\n",
      "ETHUSDT's Data Shape: (281, 1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "price_data_sanitized, sorted_available_pairs = sanitize_data(merged_price_df, start_date, end_date)\n",
    "\n",
    "if price_data_sanitized:\n",
    "    print(\"-Data Check-\")\n",
    "    keys = list(price_data_sanitized.keys())\n",
    "    count = 0\n",
    "\n",
    "    for key in keys:\n",
    "        print(\"{}'s Data Shape: {}\".format(key, price_data_sanitized[key].shape))\n",
    "        count+=1\n",
    "\n",
    "        if count == 2:\n",
    "            break\n",
    "            \n",
    "else:\n",
    "    print(\"No data found.\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6fd7de-19ee-4f9b-beee-339d2f9f5e4d",
   "metadata": {},
   "source": [
    "## Process Post Dataframe\n",
    "\n",
    "- Select the post data source. As of now, the only available options are *4chan* and *hugging_face*.\n",
    "   - To download 4chan's data, change directory into the ***'social_media_analysis'*** folder and run ***'python data_manager.py'*** in the terminal first.\n",
    "   - To download Hugging Face's data, change directory into the ***'social_media_analysis'*** folder and run ***'python download_hugging_face_data.py'*** in the terminal first.\n",
    "   - To download Telegram Channel's data, change directory into the ***'social_media_analysis'*** folder and run ***'python scrape_telegram_data.py'*** in the terminal first.\n",
    "- Write the relative directory path to the data from the current location to ***dir_path*** (eg. './social_media_analytics/saved_data/4chan/biz')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff649a-c56d-48d5-9796-ef4b99b144ad",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd006dbc-08af-4702-a24d-79f003a125b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "# Select data source. Options: ['4chan', 'hugging_face', 'telegram'].\n",
    "source = 'telegram'\n",
    "\n",
    "# Select source tag. Eg. 'biz' (source = '4chan'), '-1001164734593-SpiderCrypto Trading Journal' (source = 'telegram')\n",
    "tag = \"-1001369518127-Crypto Mumbles\"\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866bda01-fae8-4b9a-b1e2-2f813b2a209a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Comment UUID</th>\n",
       "      <th>Chat ID</th>\n",
       "      <th>Chat Title</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 23:43:25</td>\n",
       "      <td>-1001369518127-6401</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>started tapping and farming this like cookie c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02 04:19:04</td>\n",
       "      <td>-1001369518127-6407</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>you’ll qualify for the airdrop if you’ve spent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-02 16:48:03</td>\n",
       "      <td>-1001369518127-6412</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>new ฿ yearly high: ,386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-02 21:02:35</td>\n",
       "      <td>-1001369518127-6414</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>thoughts on approval?👇🏼 thumbs up - sell the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-02 21:31:24</td>\n",
       "      <td>-1001369518127-6416</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>seems like majority thinks that there won't be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-02 21:46:00</td>\n",
       "      <td>-1001369518127-6417</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>a comfy 2.5x from entry so far approaching 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-02 21:57:49</td>\n",
       "      <td>-1001369518127-6419</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>expected to launch end january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-01-02 21:59:44</td>\n",
       "      <td>-1001369518127-6420</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>recommended validators to stake with for the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-01-02 22:22:13</td>\n",
       "      <td>-1001369518127-6423</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>check your eligibility for dymension airdrop h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-01-02 22:40:23</td>\n",
       "      <td>-1001369518127-6424</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>remember to check all your wallets before the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date Time         Comment UUID         Chat ID      Chat Title  \\\n",
       "0 2024-01-01 23:43:25  -1001369518127-6401  -1001369518127  Crypto Mumbles   \n",
       "1 2024-01-02 04:19:04  -1001369518127-6407  -1001369518127  Crypto Mumbles   \n",
       "2 2024-01-02 16:48:03  -1001369518127-6412  -1001369518127  Crypto Mumbles   \n",
       "3 2024-01-02 21:02:35  -1001369518127-6414  -1001369518127  Crypto Mumbles   \n",
       "4 2024-01-02 21:31:24  -1001369518127-6416  -1001369518127  Crypto Mumbles   \n",
       "5 2024-01-02 21:46:00  -1001369518127-6417  -1001369518127  Crypto Mumbles   \n",
       "6 2024-01-02 21:57:49  -1001369518127-6419  -1001369518127  Crypto Mumbles   \n",
       "7 2024-01-02 21:59:44  -1001369518127-6420  -1001369518127  Crypto Mumbles   \n",
       "8 2024-01-02 22:22:13  -1001369518127-6423  -1001369518127  Crypto Mumbles   \n",
       "9 2024-01-02 22:40:23  -1001369518127-6424  -1001369518127  Crypto Mumbles   \n",
       "\n",
       "          User ID       Username  \\\n",
       "0  -1001369518127  cryptomumbles   \n",
       "1  -1001369518127  cryptomumbles   \n",
       "2  -1001369518127  cryptomumbles   \n",
       "3  -1001369518127  cryptomumbles   \n",
       "4  -1001369518127  cryptomumbles   \n",
       "5  -1001369518127  cryptomumbles   \n",
       "6  -1001369518127  cryptomumbles   \n",
       "7  -1001369518127  cryptomumbles   \n",
       "8  -1001369518127  cryptomumbles   \n",
       "9  -1001369518127  cryptomumbles   \n",
       "\n",
       "                                             Comment  \n",
       "0  started tapping and farming this like cookie c...  \n",
       "1  you’ll qualify for the airdrop if you’ve spent...  \n",
       "2                            new ฿ yearly high: ,386  \n",
       "3  thoughts on approval?👇🏼 thumbs up - sell the n...  \n",
       "4  seems like majority thinks that there won't be...  \n",
       "5  a comfy 2.5x from entry so far approaching 100...  \n",
       "6                     expected to launch end january  \n",
       "7  recommended validators to stake with for the c...  \n",
       "8  check your eligibility for dymension airdrop h...  \n",
       "9  remember to check all your wallets before the ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = './social_media_analysis/saved_data/{}/{}'.format(source, tag)\n",
    "merged_post_df = load_post_df_range(dir_path, source, start_date, end_date)\n",
    "\n",
    "merged_post_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079c1d27-e915-4bf3-9d1f-8eac0e97365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sample_price_df = next(iter(price_data_sanitized.items()))\n",
    "bin_datetime_df = pd.DataFrame(sample_price_df.index)\n",
    "bin_datetime_df.columns = ['Binned Date Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9631e174-8f4a-4668-8d5f-aa06330d7092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Comment UUID</th>\n",
       "      <th>Chat ID</th>\n",
       "      <th>Chat Title</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>-1001369518127-6401</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>started tapping and farming this like cookie c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6407</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>you’ll qualify for the airdrop if you’ve spent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6412</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>new ฿ yearly high: ,386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6414</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>thoughts on approval?👇🏼 thumbs up - sell the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6416</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>seems like majority thinks that there won't be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6417</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>a comfy 2.5x from entry so far approaching 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6419</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>expected to launch end january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6420</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>recommended validators to stake with for the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6423</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>check your eligibility for dymension airdrop h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>-1001369518127-6424</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>Crypto Mumbles</td>\n",
       "      <td>-1001369518127</td>\n",
       "      <td>cryptomumbles</td>\n",
       "      <td>remember to check all your wallets before the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date Time         Comment UUID         Chat ID      Chat Title  \\\n",
       "0 2024-01-01  -1001369518127-6401  -1001369518127  Crypto Mumbles   \n",
       "1 2024-01-02  -1001369518127-6407  -1001369518127  Crypto Mumbles   \n",
       "2 2024-01-02  -1001369518127-6412  -1001369518127  Crypto Mumbles   \n",
       "3 2024-01-02  -1001369518127-6414  -1001369518127  Crypto Mumbles   \n",
       "4 2024-01-02  -1001369518127-6416  -1001369518127  Crypto Mumbles   \n",
       "5 2024-01-02  -1001369518127-6417  -1001369518127  Crypto Mumbles   \n",
       "6 2024-01-02  -1001369518127-6419  -1001369518127  Crypto Mumbles   \n",
       "7 2024-01-02  -1001369518127-6420  -1001369518127  Crypto Mumbles   \n",
       "8 2024-01-02  -1001369518127-6423  -1001369518127  Crypto Mumbles   \n",
       "9 2024-01-02  -1001369518127-6424  -1001369518127  Crypto Mumbles   \n",
       "\n",
       "          User ID       Username  \\\n",
       "0  -1001369518127  cryptomumbles   \n",
       "1  -1001369518127  cryptomumbles   \n",
       "2  -1001369518127  cryptomumbles   \n",
       "3  -1001369518127  cryptomumbles   \n",
       "4  -1001369518127  cryptomumbles   \n",
       "5  -1001369518127  cryptomumbles   \n",
       "6  -1001369518127  cryptomumbles   \n",
       "7  -1001369518127  cryptomumbles   \n",
       "8  -1001369518127  cryptomumbles   \n",
       "9  -1001369518127  cryptomumbles   \n",
       "\n",
       "                                             Comment  \n",
       "0  started tapping and farming this like cookie c...  \n",
       "1  you’ll qualify for the airdrop if you’ve spent...  \n",
       "2                            new ฿ yearly high: ,386  \n",
       "3  thoughts on approval?👇🏼 thumbs up - sell the n...  \n",
       "4  seems like majority thinks that there won't be...  \n",
       "5  a comfy 2.5x from entry so far approaching 100...  \n",
       "6                     expected to launch end january  \n",
       "7  recommended validators to stake with for the c...  \n",
       "8  check your eligibility for dymension airdrop h...  \n",
       "9  remember to check all your wallets before the ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use pd.merge_asof to align to bin_datetime_df\n",
    "post_data_binned_df = pd.merge_asof(merged_post_df, bin_datetime_df, left_on='Date Time', right_on='Binned Date Time')\n",
    "post_data_binned_df['Date Time'] = post_data_binned_df['Binned Date Time']\n",
    "post_data_binned_df = post_data_binned_df.drop(columns=['Binned Date Time'])\n",
    "post_data_binned_df = post_data_binned_df.dropna(subset=['Date Time'])\n",
    "post_data_binned_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9437b1-5700-4121-95bb-a01b41b9e1b1",
   "metadata": {},
   "source": [
    "## Load Pre-saved Sentiment Scores \n",
    "\n",
    "The purpose of this section is to identify which datetimes already have sentiment scores. If a datetime has a score, the LLM will skip performing sentiment analysis for that datetime. This helps to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f3e471c-9f30-4809-9dee-b69f9c798343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Presaved Sentiment Score:\n",
      "Empty DataFrame\n",
      "Columns: [Open Time, Sentiment Score]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Presaved Normalised Sentiment Score:\n",
      "Empty DataFrame\n",
      "Columns: [Open Time, Sentiment Score]\n",
      "Index: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "presaved_sentiment_score_df_base = pd.DataFrame(columns=['Open Time', 'Sentiment Score'])\n",
    "sentiment_score_dir_path = './saved_data/sentiment_score/{}/{}/{}'.format(source, tag, cex + '_' + interval)\n",
    "normalised_sentiment_score_dir_path = './saved_data/normalised_sentiment_score/{}/{}/{}'.format(source, tag, cex + '_' + interval)\n",
    "\n",
    "presaved_sentiment_score_df, _ = load_presaved_df(presaved_sentiment_score_df_base, sentiment_score_dir_path)\n",
    "presaved_normalised_sentiment_score_df, _ = load_presaved_df(presaved_sentiment_score_df_base, normalised_sentiment_score_dir_path)\n",
    "\n",
    "print(\"Presaved Sentiment Score:\")\n",
    "print(presaved_sentiment_score_df.tail(5))\n",
    "print(\"\\n\")\n",
    "print(\"Presaved Normalised Sentiment Score:\")\n",
    "print(presaved_normalised_sentiment_score_df.tail(5))\n",
    "\n",
    "presaved_sentiment_score_datetime_dict = pd.Series(True, index=presaved_sentiment_score_df['Open Time']).to_dict()\n",
    "presaved_normalised_sentiment_score_datetime_dict = pd.Series(True, index=presaved_normalised_sentiment_score_df['Open Time']).to_dict()\n",
    "\n",
    "overlapped_datetime = set(presaved_sentiment_score_datetime_dict.keys()).intersection(presaved_normalised_sentiment_score_datetime_dict.keys())\n",
    "overlapped_presaved_datetime_dict = {datetime: True for datetime in overlapped_datetime}\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73980eb-c021-4ad4-bee5-463e0a26595a",
   "metadata": {},
   "source": [
    "## Initialise LLM and Checking LLM Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7af97967-f4b3-4a39-8688-3de842e1db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /ElKulako/cryptobert/resolve/main/tokenizer_config.json (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x178a31510>: Failed to establish a new connection: [Errno 61] Connection refused')))' thrown while requesting HEAD https://huggingface.co/ElKulako/cryptobert/resolve/main/tokenizer_config.json\n"
     ]
    },
    {
     "ename": "ProxyError",
     "evalue": "HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /ElKulako/cryptobert/resolve/main/tokenizer_config.json (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x178a31510>: Failed to establish a new connection: [Errno 61] Connection refused')))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/util/connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:700\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_new_proxy_conn \u001b[38;5;129;01mand\u001b[39;00m http_tunnel_required:\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:996\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    994\u001b[0m     conn\u001b[38;5;241m.\u001b[39mtls_in_tls_required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 996\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x178a31510>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /ElKulako/cryptobert/resolve/main/tokenizer_config.json (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x178a31510>: Failed to establish a new connection: [Errno 61] Connection refused')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElKulako/cryptobert\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name,\n\u001b[1;32m      4\u001b[0m                                                            num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:598\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 598\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    600\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:442\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03mLoads the tokenizer configuration from a pretrained model tokenizer configuration.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03mtokenizer_config = get_tokenizer_config(\"tokenizer-test\")\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[1;32m    441\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 442\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/hub.py:409\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    406\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:124\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    120\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(\n\u001b[1;32m    121\u001b[0m         fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1106\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m http_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1115\u001b[0m             HUGGINGFACE_HEADER_X_REPO_COMMIT\n\u001b[1;32m   1116\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:124\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    120\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(\n\u001b[1;32m    121\u001b[0m         fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1432\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1429\u001b[0m headers \u001b[38;5;241m=\u001b[39m build_hf_headers(token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1432\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1440\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1441\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:405\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# 2. Force relative redirection\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 405\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:440\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# 3. Exponential backoff\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mConnectTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mProxyError\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:148\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m thrown while requesting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nb_tries \u001b[38;5;241m>\u001b[39m max_retries:\n\u001b[0;32m--> 148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Sleep for X seconds\u001b[39;00m\n\u001b[1;32m    151\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms [Retry \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnb_tries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:129\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/adapters.py:694\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _ProxyError):\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mProxyError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /ElKulako/cryptobert/resolve/main/tokenizer_config.json (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x178a31510>: Failed to establish a new connection: [Errno 61] Connection refused')))"
     ]
    }
   ],
   "source": [
    "model_name = \"ElKulako/cryptobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                           num_labels=3)\n",
    "max_length = 128\n",
    "pipe = TextClassificationPipeline(model=model,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  max_length=max_length,                           # original max_length is 64\n",
    "                                  truncation=True,\n",
    "                                  padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00af3f6-338a-4ed9-a385-c5207d597414",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_datetime_comments_dict = {}\n",
    "num_tokens_count_dict = {}\n",
    "\n",
    "for _, row in post_data_binned_df.iterrows():\n",
    "    bin_datetime = row['Date Time']\n",
    "    bin_comment = row['Comment']\n",
    "    tokens = tokenizer.tokenize(bin_comment)\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    if num_tokens not in num_tokens_count_dict:\n",
    "        num_tokens_count_dict[num_tokens] = 1\n",
    "    else:\n",
    "        num_tokens_count_dict[num_tokens] += 1\n",
    "        \n",
    "    if bin_datetime not in binned_datetime_comments_dict:\n",
    "        binned_datetime_comments_dict[bin_datetime] = []\n",
    "\n",
    "    binned_datetime_comments_dict[bin_datetime].append(bin_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1837b3-2e60-4c5f-bc35-74264264da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "num_tokens = list(num_tokens_count_dict.keys())\n",
    "counts = list(num_tokens_count_dict.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(num_tokens, counts)\n",
    "plt.axvline(x=max_length, color='red', linestyle='--', label='Truncation Point')\n",
    "\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Count of Comments')\n",
    "plt.title('Histogram of Number of Tokens')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba93c91-961b-4fab-b6a0-5f5f7227b885",
   "metadata": {},
   "source": [
    "## Use LLM to perform Sentiment Analysis\n",
    "\n",
    "This part will take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4363d-4ba2-482f-8913-1469da00f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "post_bin_datetime_list = []\n",
    "post_bin_sentiment_score_list = []\n",
    "post_bin_normalised_sentiment_score_list = []\n",
    "\n",
    "for bin_datetime, comments in binned_datetime_comments_dict.items():\n",
    "\n",
    "    if bin_datetime in overlapped_presaved_datetime_dict:\n",
    "        continue\n",
    "\n",
    "    print(\"Performing sentiment analysis on comments in Date Time {} bin...\".format(bin_datetime))\n",
    "    \n",
    "    sentiment_preds = pipe(comments)\n",
    "    bin_sentiment_score = 0\n",
    "    \n",
    "    for sentiment_pred in sentiment_preds:\n",
    "        if sentiment_pred['label'].lower() == 'bullish':\n",
    "            bin_sentiment_score += sentiment_pred['score']\n",
    "        elif sentiment_pred['label'].lower() == 'bearish':\n",
    "            bin_sentiment_score -= sentiment_pred['score']\n",
    "\n",
    "    bin_normalised_sentiment_score = bin_sentiment_score / len(sentiment_preds)\n",
    "\n",
    "    post_bin_datetime_list.append(bin_datetime)\n",
    "    post_bin_sentiment_score_list.append(bin_sentiment_score)\n",
    "    post_bin_normalised_sentiment_score_list.append(bin_normalised_sentiment_score)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad2072-0a95-4eb7-ae70-bca3a2b04437",
   "metadata": {},
   "source": [
    "## Save and Check Sentiment Score Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce4af6-c113-4def-b21e-9776077d15e3",
   "metadata": {},
   "source": [
    "### Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b412c58-2a44-46f2-b373-2981d6d311f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "binned_sentiment_score_df = pd.DataFrame({\n",
    "    'Open Time': post_bin_datetime_list,\n",
    "    'Sentiment Score': post_bin_sentiment_score_list\n",
    "})\n",
    "\n",
    "binned_sentiment_score_df = save_sentiment_score_df(binned_sentiment_score_df, sentiment_score_dir_path, start_date, end_date)\n",
    "binned_sentiment_score_df = binned_sentiment_score_df.set_index('Open Time')\n",
    "\n",
    "print(\"Sentiment Score:\")\n",
    "print(binned_sentiment_score_df.head(5))\n",
    "print(binned_sentiment_score_df.tail(5))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987672d6-8d7f-4812-acc2-450b7601bad7",
   "metadata": {},
   "source": [
    "### Normalised Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d12187-3117-4c20-bd5c-b32d811c21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "binned_normalised_sentiment_score_df = pd.DataFrame({\n",
    "    'Open Time': post_bin_datetime_list,\n",
    "    'Sentiment Score': post_bin_normalised_sentiment_score_list\n",
    "})\n",
    "\n",
    "binned_normalised_sentiment_score_df = save_sentiment_score_df(binned_normalised_sentiment_score_df, normalised_sentiment_score_dir_path, start_date, end_date)\n",
    "binned_normalised_sentiment_score_df = binned_normalised_sentiment_score_df.set_index('Open Time')\n",
    "\n",
    "print(\"Normalised Sentiment Score:\")\n",
    "print(binned_normalised_sentiment_score_df.head(5))\n",
    "print(binned_normalised_sentiment_score_df.tail(5))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac0df0-c7d9-4b08-b764-82329b227c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSelectable pairs:\")\n",
    "\n",
    "for pair in sorted_available_pairs:\n",
    "    print(\"- {}\".format(pair))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f94d4c-a0b6-4f88-a6f0-d3f563bde9ed",
   "metadata": {},
   "source": [
    "## Select Pairs for Detailed Analysis\n",
    "\n",
    "- Please select any pair combination from the output below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e4a88f-e561-49c9-87ba-0d7ebd5bda9b",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa7502-8d14-4e8b-a874-0d74da75913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "ticker_pairs = [\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"]\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04baf7f9-2f3c-48bb-97ad-5fd904f1f310",
   "metadata": {},
   "source": [
    "## Plot Function\n",
    "\n",
    "Bullish sentiment is highlighted in the chart as green and bearish sentiment is highlighted in the chart as red. The alpha of the colours (opacity) represent the score of the sentiment. The higher the sentiment score, the higher the alpha value of the color (more opaque)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1baec-4537-44f7-841d-7c3b37bd48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_on_chart(ticker_pairs, price_data_sanitized, binned_sentiment_score_df):\n",
    "    fig, axs = plt.subplots(len(ticker_pairs), 1, figsize=(18, 14))\n",
    "    if len(ticker_pairs) == 1:\n",
    "        axs = [axs]\n",
    "    \n",
    "    for i, ticker in enumerate(ticker_pairs):\n",
    "    \n",
    "        if ticker not in sorted_available_pairs:\n",
    "            print(\"{} is not found in the list of selectable pairs. Please choose another one.\".format(ticker))\n",
    "            continue\n",
    "    \n",
    "        price_data = price_data_sanitized[ticker]['Close']\n",
    "        open_time = price_data_sanitized[ticker].index\n",
    "        sentiment_score = binned_sentiment_score_df['Sentiment Score']\n",
    "        sentiment_score = sentiment_score.reindex(open_time)\n",
    "        sentiment_score = sentiment_score.fillna(0)\n",
    "        max_abs_sentiment_score = sentiment_score.abs().max()\n",
    "        sentiment_score_normalized = (sentiment_score / max_abs_sentiment_score) * 0.5\n",
    "        \n",
    "        axs[i].plot(open_time, price_data, label=f'{ticker}', color='gray', alpha=0.7)\n",
    "    \n",
    "        # Apply rolling mean with a window of 15\n",
    "        price_data_smooth = price_data.rolling(window=15, min_periods=1).mean()\n",
    "        axs[i].plot(open_time, price_data_smooth, label=f'{ticker} SMA', color='blue')\n",
    "    \n",
    "        if len(open_time) > 1:\n",
    "            # Plot sentiment score regions\n",
    "            for j in range(len(sentiment_score_normalized) - 1):\n",
    "                start_time = open_time[j]\n",
    "                end_time = open_time[j + 1]\n",
    "                \n",
    "                if sentiment_score_normalized.iloc[j] > 0.2:\n",
    "                    axs[i].axvspan(start_time, end_time, color='green', alpha=sentiment_score_normalized.iloc[j])\n",
    "                elif sentiment_score_normalized.iloc[j] < 0:\n",
    "                    axs[i].axvspan(start_time, end_time, color='red', alpha=abs(sentiment_score_normalized.iloc[j]))\n",
    "        \n",
    "            # Handling the last bin if necessary\n",
    "            last_time = open_time[-1]\n",
    "            next_time = last_time + (open_time[-1] - open_time[-2])  # Assumes last bin has the same duration\n",
    "            if sentiment_score_normalized.iloc[-1] > 0.2:\n",
    "                axs[i].axvspan(last_time, next_time, color='green', alpha=sentiment_score_normalized.iloc[-1])\n",
    "            elif sentiment_score_normalized.iloc[-1] < 0:\n",
    "                axs[i].axvspan(last_time, next_time, color='red', alpha=abs(sentiment_score_normalized.iloc[-1]))\n",
    "    \n",
    "        green_patch = mpatches.Patch(color='green', label='Bullish Sentiment')\n",
    "        red_patch = mpatches.Patch(color='red', label='Bearish Sentiment')\n",
    "    \n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        handles.extend([green_patch, red_patch])\n",
    "        labels.extend(['Bullish Sentiment', 'Bearish Sentiment'])\n",
    "    \n",
    "        axs[i].set_ylabel('Price ($)', fontsize=18)\n",
    "        axs[i].set_xlabel('Open Time', fontsize=18)\n",
    "        axs[i].set_title(f'{ticker}', fontsize=24)\n",
    "        axs[i].legend(handles=handles, labels=labels, loc='best')\n",
    "        axs[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecf0d2-03a3-4fa8-b4d4-1da11584f558",
   "metadata": {},
   "source": [
    "### Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efac017-e6cd-4e6e-acf9-fe5f3467e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "plot_sentiment_on_chart(ticker_pairs, price_data_sanitized, binned_sentiment_score_df)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa131ed8-bd5c-4b50-9ff3-67e64dfc4735",
   "metadata": {},
   "source": [
    "### Normalised Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e2b44-e5fd-4475-8272-e6c21e42278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "plot_sentiment_on_chart(ticker_pairs, price_data_sanitized, binned_normalised_sentiment_score_df)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a09a4-eedc-4bbd-b24e-f972ba5045f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypto-trading-analysis",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.659839,
   "end_time": "2023-11-01T02:04:21.309361",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-01T02:03:46.649522",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
